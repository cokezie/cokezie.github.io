---
title: "Mapping Code Quality"
image: featured.jpg
categories:
  - Data Collection
  - Python Coding
  - Machine Learning
about: 
  template: solana
  image: featured.jpg
---

A project that I worked on with professor Marouane Kessentini of the University of Michigan-Flint and Mr. Mohamed Almukhtar, a University of Michigan-Flint doctoral student, focused on the creation of foundational work for automating quality enhancement changes in machine learning-powered accessibility software.

In this project, we conducted an empirical study using open-source GitHub projects to access and focus on quality metrics of code commits and compare them with their parent commits. The insights gained from this comparison will help us determine whether our chosen quality metrics have improved over time. We then evaluated our novel quality metric assessment tool against the dataset generated from our empirical study, measuring Cohen’s kappa score, accuracy, recall, and other metrics with the goal of assessing the validity of our collected data and tool. When our tool was fine tuned and gave us the accuracy score that we had aimed for, we utilized the tool to analyze even larger code commits, eventually analyzing the changes in over 1,000 code commits.

From the analysis, we gained insight into the specific details that enhance our studied metrics, enabling us to be able to develop a comprehensive taxonomy of our work and what we’ve learned. This taxonomy outlines each of the changes that contributed to the enhancement of each quality metric. The creation and work done on this taxonomy accomplished our original goal of creating a foundational work for automating quality enhancement changes in machine learning-powered software for enhancing accessibility for all.

**Product**:

*Link to published paper coming soon, February 2024.*